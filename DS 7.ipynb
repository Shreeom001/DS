{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "603aed11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\jayes\\miniconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jayes\\miniconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: click in c:\\users\\jayes\\miniconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jayes\\miniconda3\\lib\\site-packages (from nltk) (2024.4.28)\n",
      "Requirement already satisfied: joblib in c:\\users\\jayes\\miniconda3\\lib\\site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jayes\\miniconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "012ac64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jayes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jayes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jayes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')  # Download tokenizer resources\n",
    "nltk.download('stopwords')  # Download stop words list (optional for stop word removal)\n",
    "nltk.download('wordnet')  # Download resources for stemming/lemmatization (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e5ea6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natural', 'language', 'processing', '(nlp)', 'is', 'a', 'subfield', 'of', 'artificial', 'intelligence', 'that', 'deals', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language.', 'in', 'particular,', 'nlp', 'is', 'concerned', 'with', 'the', 'ability', 'of', 'computers', 'to', 'understand', 'and', 'manipulate', 'human', 'language', 'in', 'a', 'way', 'that', 'is', 'natural', 'to', 'humans.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Natural language processing (NLP) is a subfield of artificial intelligence that deals with the interactions between computers and human language. In particular, NLP is concerned with the ability of computers to understand and manipulate human language in a way that is natural to humans.\"\n",
    "\n",
    "tokens = text.lower().split()  # Lowercase and split into tokens\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd8a6e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natural', 'language', 'processing', '(nlp)', 'subfield', 'artificial', 'intelligence', 'deals', 'interactions', 'computers', 'human', 'language.', 'particular,', 'nlp', 'concerned', 'ability', 'computers', 'understand', 'manipulate', 'human', 'language', 'way', 'natural', 'humans.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords  # Import stopwords list\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "tokens_filtered = [token for token in tokens if token not in stop_words]\n",
    "print(tokens_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea4c75ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natur', 'languag', 'process', '(nlp)', 'subfield', 'artifici', 'intellig', 'deal', 'interact', 'comput', 'human', 'language.', 'particular,', 'nlp', 'concern', 'abil', 'comput', 'understand', 'manipul', 'human', 'languag', 'way', 'natur', 'humans.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "tokens_stemmed = [stemmer.stem(token) for token in tokens_filtered]\n",
    "print(tokens_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cdc093cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natural', 'language', 'processing', '(nlp)', 'subfield', 'artificial', 'intelligence', 'deal', 'interaction', 'computer', 'human', 'language.', 'particular,', 'nlp', 'concerned', 'ability', 'computer', 'understand', 'manipulate', 'human', 'language', 'way', 'natural', 'humans.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokens_lemmatized = [lemmatizer.lemmatize(token) for token in tokens_filtered]\n",
    "print(tokens_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c1ee2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'natural': 2,\n",
       "         'language': 2,\n",
       "         'computer': 2,\n",
       "         'human': 2,\n",
       "         'processing': 1,\n",
       "         '(nlp)': 1,\n",
       "         'subfield': 1,\n",
       "         'artificial': 1,\n",
       "         'intelligence': 1,\n",
       "         'deal': 1,\n",
       "         'interaction': 1,\n",
       "         'language.': 1,\n",
       "         'particular,': 1,\n",
       "         'nlp': 1,\n",
       "         'concerned': 1,\n",
       "         'ability': 1,\n",
       "         'understand': 1,\n",
       "         'manipulate': 1,\n",
       "         'way': 1,\n",
       "         'humans.': 1})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_frequencies = Counter(preprocessed_text)\n",
    "term_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64848f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'natural': 1,\n",
       " 'language': 1,\n",
       " 'processing': 1,\n",
       " '(nlp)': 1,\n",
       " 'subfield': 1,\n",
       " 'artificial': 1,\n",
       " 'intelligence': 1,\n",
       " 'deal': 1,\n",
       " 'interaction': 1,\n",
       " 'computer': 1,\n",
       " 'human': 1,\n",
       " 'language.': 1,\n",
       " 'particular,': 1,\n",
       " 'nlp': 1,\n",
       " 'concerned': 1,\n",
       " 'ability': 1,\n",
       " 'understand': 1,\n",
       " 'manipulate': 1,\n",
       " 'way': 1,\n",
       " 'humans.': 1}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_frequency = {term: 1 for term in term_frequencies}\n",
    "document_frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4223869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'natural': -1.3862943611198906, 'language': -1.3862943611198906, 'processing': -0.6931471805599453, '(nlp)': -0.6931471805599453, 'subfield': -0.6931471805599453, 'artificial': -0.6931471805599453, 'intelligence': -0.6931471805599453, 'deal': -0.6931471805599453, 'interaction': -0.6931471805599453, 'computer': -1.3862943611198906, 'human': -1.3862943611198906, 'language.': -0.6931471805599453, 'particular,': -0.6931471805599453, 'nlp': -0.6931471805599453, 'concerned': -0.6931471805599453, 'ability': -0.6931471805599453, 'understand': -0.6931471805599453, 'manipulate': -0.6931471805599453, 'way': -0.6931471805599453, 'humans.': -0.6931471805599453}\n"
     ]
    }
   ],
   "source": [
    "tf_idf = {term: term_frequencies[term] * idf[term] for term in term_frequencies}\n",
    "\n",
    "# Print TF-IDF scores for each term\n",
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef5697b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
